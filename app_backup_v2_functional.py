import os
import sys
import json
import time
import wave
import threading
import queue
from datetime import datetime
from pathlib import Path
import pyaudio
import keyboard
from faster_whisper import WhisperModel
from colorama import init, Fore, Style

# Initialiser colorama pour les couleurs dans le terminal
init()

# CORRECTION: D√©sactiver les symlinks pour √©viter l'erreur de privil√®ges Windows
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
os.environ["HF_HUB_DISABLE_SYMLINKS"] = "1"

import tempfile
import threading
import wave
import pyaudio
import keyboard
import pyautogui
import tkinter as tk
from tkinter import ttk, Canvas
import time
import pyperclip
from faster_whisper import WhisperModel

class VoiceTranscriptionApp:
    def __init__(self):
        # Configuration audio
        self.chunk = 1024
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000
        self.recording = False
        self.audio_data = []
        self.running = True
        self.microphone_name = "TONOR TD510 Dynamic Mic"
        self.microphone_index = None

        # Buffer pour la derni√®re transcription
        self.last_transcription = ""

        # Queue pour l'indicateur de transcription
        self.transcription_queue = queue.Queue()
        self.transcription_indicator_window = None
        
        # Initiali
        # sation PyAudio
        self.audio = pyaudio.PyAudio()
        
        # Trouver le microphone sp√©cifique
        self._find_microphone()
        
        # D√©tection automatique du GPU
        device = "cuda" if self._check_gpu() else "cpu"
        compute_type = "float16" if device == "cuda" else "int8"
        
        print(f"Initialisation du mod√®le Whisper large-v3 sur {device} avec compute_type {compute_type}")
        
        # Initialisation du mod√®le Whisper large-v3 comme demand√©
        self.model = WhisperModel(
            "large-v3",  # Mod√®le large-v3 comme sp√©cifi√©
            device=device,
            compute_type=compute_type,
            cpu_threads=4 if device == "cpu" else 4
        )
        
        # Configuration des raccourcis clavier
        keyboard.add_hotkey('ctrl+f9', self.toggle_recording)
        keyboard.add_hotkey('ctrl+shift+f9', self.reinject_last_transcription)
        keyboard.add_hotkey('ctrl+f10', self.quit_app)

        # Indicateur visuel d'enregistrement
        self.indicator_window = None
        self.indicator_thread = None

        print("Application pr√™te !")
        print("Appuyez sur Ctrl+F9 pour commencer/arr√™ter l'enregistrement")
        print("Appuyez sur Ctrl+Shift+F9 pour r√©injecter la derni√®re transcription")
        print("Appuyez sur Ctrl+F10 pour quitter")
        if self.microphone_index is not None:
            print(f"Microphone s√©lectionn√©: {self.microphone_name}")
        else:
            print("Attention: Microphone TONOR TD510 Dynamic Mic non trouv√©, utilisation du microphone par d√©faut")

        # Afficher l'indicateur "mod√®le charg√©"
        self.show_ready_indicator()
    
    def _check_gpu(self):
        """V√©rifie la disponibilit√© du GPU CUDA"""
        try:
            import torch
            return torch.cuda.is_available()
        except ImportError:
            # V√©rification alternative sans torch
            try:
                import ctranslate2
                return ctranslate2.get_cuda_device_count() > 0
            except:
                return False
    
    def _find_microphone(self):
        """Trouve l'index du microphone TONOR TD510 Dynamic Mic"""
        print("Recherche du microphone TONOR TD510 Dynamic Mic...")
        
        for i in range(self.audio.get_device_count()):
            device_info = self.audio.get_device_info_by_index(i)
            device_name = device_info.get('name', '')
            
            # V√©rifier si c'est un p√©riph√©rique d'entr√©e
            if device_info.get('maxInputChannels', 0) > 0:
                print(f"Microphone trouv√©: {device_name} (index: {i})")
                
                # Recherche du microphone TONOR (recherche flexible)
                if "tonor" in device_name.lower() or "td510" in device_name.lower():
                    self.microphone_index = i
                    print(f"‚úÖ Microphone TONOR trouv√© √† l'index {i}")
                    return
        
        print("‚ö†Ô∏è Microphone TONOR TD510 Dynamic Mic non trouv√©, utilisation du microphone par d√©faut")
    
    def toggle_recording(self):
        """D√©marre ou arr√™te l'enregistrement"""
        if not self.recording:
            self.start_recording()
        else:
            self.stop_recording()

    def start_recording(self):
        """D√©marre l'enregistrement audio"""
        if self.recording:
            return
        
        print("üé§ D√©but de l'enregistrement...")
        self.recording = True
        self.audio_data = []
        self.show_recording_indicator()
        
        # Configuration du stream audio avec le microphone sp√©cifique
        try:
            stream_kwargs = {
                'format': self.format,
                'channels': self.channels,
                'rate': self.rate,
                'input': True,
                'frames_per_buffer': self.chunk
            }
            
            # Utiliser le microphone sp√©cifique s'il est trouv√©
            if self.microphone_index is not None:
                stream_kwargs['input_device_index'] = self.microphone_index
            
            self.stream = self.audio.open(**stream_kwargs)
            
            # Thread pour l'enregistrement
            self.record_thread = threading.Thread(target=self._record_audio)
            self.record_thread.start()
            
        except Exception as e:
            print(f"Erreur lors de l'ouverture du stream audio: {e}")
            self.recording = False
    
    def _record_audio(self):
        """Enregistre l'audio en continu"""
        while self.recording:
            try:
                data = self.stream.read(self.chunk, exception_on_overflow=False)
                self.audio_data.append(data)
            except Exception as e:
                print(f"Erreur lors de l'enregistrement: {e}")
                break
    
    def stop_recording(self):
        """Arr√™te l'enregistrement et transcrit"""
        if not self.recording:
            return
        
        print("‚èπÔ∏è Arr√™t de l'enregistrement...")
        self.recording = False
        self.hide_recording_indicator()
        
        # Attendre la fin du thread d'enregistrement
        if hasattr(self, 'record_thread'):
            self.record_thread.join()
        
        # Fermer le stream
        if hasattr(self, 'stream'):
            self.stream.stop_stream()
            self.stream.close()
        
        # Sauvegarder et transcrire
        if self.audio_data:
            self.save_and_transcribe()
    
    def show_transcription_indicator(self):
        """Affiche l'indicateur de progression de transcription"""
        def create_transcription_indicator():
            try:
                indicator = tk.Tk()
                indicator.title("Transcription")
                indicator.configure(bg='#3b82f6')  # Bleu moderne
                indicator.overrideredirect(True)
                indicator.attributes('-topmost', True)
                indicator.attributes('-alpha', 0.95)

                # Positionner en haut √† droite (sous l'indicateur REC)
                indicator.update_idletasks()
                screen_width = indicator.winfo_screenwidth()
                win_width = 350
                win_height = 100
                x_pos = screen_width - win_width - 20
                y_pos = 80  # En dessous de l'indicateur REC qui est √† y=20
                indicator.geometry(f"{win_width}x{win_height}+{x_pos}+{y_pos}")

                # Label pour le statut (segment X)
                status_label = tk.Label(indicator, text="‚è≥ Transcription...",
                                      bg='#3b82f6', fg='white',
                                      font=('Segoe UI', 12, 'bold'))
                status_label.pack(pady=(10, 5))

                # Label pour le texte transcrit (derniers caract√®res)
                text_label = tk.Label(indicator, text="",
                                    bg='#3b82f6', fg='white',
                                    font=('Segoe UI', 9),
                                    wraplength=330,
                                    justify='left')
                text_label.pack(pady=(0, 10), padx=10)

                # Stocker la r√©f√©rence
                self.transcription_indicator_window = indicator

                # Fonction pour mettre √† jour l'indicateur depuis la queue
                def update_from_queue():
                    try:
                        # Lire tous les messages disponibles dans la queue
                        while True:
                            msg_type, msg_data = self.transcription_queue.get_nowait()

                            if msg_type == "segment":
                                current_seg, text = msg_data
                                status_label.config(text=f"‚è≥ Transcription... (segment {current_seg})")
                                # Afficher les 120 derniers caract√®res
                                display_text = text[-120:] if len(text) > 120 else text
                                text_label.config(text=display_text)

                            elif msg_type == "done":
                                status_label.config(text="‚úì Transcription termin√©e")
                                text_label.config(text="Injection du texte...")
                                # Fermer apr√®s 2 secondes
                                indicator.after(2000, lambda: self._close_transcription_indicator(indicator))
                                return

                            elif msg_type == "error":
                                status_label.config(text="‚ùå Erreur")
                                text_label.config(text=str(msg_data))
                                indicator.after(3000, lambda: self._close_transcription_indicator(indicator))
                                return

                    except queue.Empty:
                        pass

                    # Continuer √† v√©rifier la queue toutes les 100ms
                    if self.transcription_indicator_window:
                        indicator.after(100, update_from_queue)

                # D√©marrer la v√©rification de la queue
                update_from_queue()

                # Maintenir la fen√™tre ouverte
                indicator.mainloop()

            except Exception as e:
                print(f"Erreur cr√©ation indicateur transcription: {e}")

        # Lancer l'indicateur dans un thread s√©par√©
        indicator_thread = threading.Thread(target=create_transcription_indicator, daemon=True)
        indicator_thread.start()
        time.sleep(0.15)  # Laisser le temps √† la fen√™tre de se cr√©er

    def _close_transcription_indicator(self, indicator):
        """Ferme l'indicateur de transcription"""
        try:
            if indicator:
                indicator.quit()
                indicator.destroy()
                self.transcription_indicator_window = None
        except Exception as e:
            print(f"Erreur fermeture indicateur transcription: {e}")

    def save_and_transcribe(self):
        """Sauvegarde l'audio et effectue la transcription"""
        # Afficher l'indicateur de progression
        self.show_transcription_indicator()

        # Cr√©er un fichier temporaire
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
            temp_filename = temp_file.name

            # Sauvegarder l'audio
            with wave.open(temp_filename, 'wb') as wf:
                wf.setnchannels(self.channels)
                wf.setsampwidth(self.audio.get_sample_size(self.format))
                wf.setframerate(self.rate)
                wf.writeframes(b''.join(self.audio_data))

        print("üîÑ Transcription en cours avec le mod√®le large-v3...")

        try:
            # Transcription avec faster-whisper selon les bonnes pratiques
            segments, info = self.model.transcribe(
                temp_filename,
                language=None,  # D√©tection automatique de la langue
                task="transcribe",
                vad_filter=True,  # Filtrage de l'activit√© vocale
                vad_parameters={"min_silence_duration_ms": 500},
                word_timestamps=False,
                beam_size=5,
                best_of=5,
                temperature=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0],
                compression_ratio_threshold=2.4,
                log_prob_threshold=-1.0,
                no_speech_threshold=0.6,
                condition_on_previous_text=True
            )

            # R√©cup√©rer le texte transcrit avec mise √† jour progressive
            # NE PAS convertir en liste pour √©viter de bloquer sur de longs audios
            transcription = ""
            segment_count = 0
            for segment in segments:
                segment_count += 1
                transcription += segment.text
                # Envoyer une mise √† jour √† l'indicateur (sans total pour √©viter le blocage)
                self.transcription_queue.put(("segment", (segment_count, transcription)))

            transcription = transcription.strip()

            if transcription:
                print(f"‚úÖ Transcription ({info.language}): {transcription}")
                # Sauvegarder dans le buffer avant d'injecter
                self.last_transcription = transcription
                # Signaler que la transcription est termin√©e
                self.transcription_queue.put(("done", None))
                # Ins√©rer le texte √† la position du curseur avec support des accents
                self.insert_text_with_accents(transcription)
            else:
                print("‚ùå Aucune parole d√©tect√©e")
                self.transcription_queue.put(("error", "Aucune parole d√©tect√©e"))

        except Exception as e:
            print(f"Erreur lors de la transcription: {e}")
            self.transcription_queue.put(("error", str(e)))

        finally:
            # Nettoyer le fichier temporaire
            try:
                os.unlink(temp_filename)
            except:
                pass
    
    def reinject_last_transcription(self):
        """R√©injecte la derni√®re transcription au curseur"""
        if self.last_transcription:
            print(f"üìã R√©injection de la derni√®re transcription: {self.last_transcription}")
            self.insert_text_with_accents(self.last_transcription)
        else:
            print("‚ö†Ô∏è Aucune transcription dans le buffer")

    def insert_text_with_accents(self, text):
        """Ins√®re du texte avec support des caract√®res accentu√©s"""
        try:
            # M√©thode 1: Utiliser le presse-papiers (plus fiable pour les accents)
            # Sauvegarder le contenu actuel du presse-papiers
            try:
                original_clipboard = pyperclip.paste()
            except:
                original_clipboard = ""
            
            # Copier le texte transcrit dans le presse-papiers
            pyperclip.copy(text)
            
            # Petit d√©lai pour s'assurer que le presse-papiers est mis √† jour
            time.sleep(0.1)
            
            # Coller le texte avec Ctrl+V
            pyautogui.hotkey('ctrl', 'v')
            
            # Petit d√©lai avant de restaurer le presse-papiers
            time.sleep(0.2)
            
            # Restaurer le contenu original du presse-papiers
            try:
                pyperclip.copy(original_clipboard)
            except:
                pass
                
        except Exception as e:
            print(f"Erreur lors de l'insertion du texte: {e}")
            # Fallback: essayer avec pyautogui (sans accents)
            try:
                # Remplacer les caract√®res accentu√©s par leurs √©quivalents
                text_fallback = (text.replace('√©', 'e').replace('√®', 'e').replace('√™', 'e')
                               .replace('√†', 'a').replace('√¢', 'a').replace('√§', 'a')
                               .replace('√π', 'u').replace('√ª', 'u').replace('√º', 'u')
                               .replace('√¥', 'o').replace('√∂', 'o').replace('√≤', 'o')
                               .replace('√Æ', 'i').replace('√Ø', 'i').replace('√¨', 'i')
                               .replace('√ß', 'c').replace('√±', 'n')
                               .replace('√â', 'E').replace('√à', 'E').replace('√ä', 'E')
                               .replace('√Ä', 'A').replace('√Ç', 'A').replace('√Ñ', 'A')
                               .replace('√ô', 'U').replace('√õ', 'U').replace('√ú', 'U')
                               .replace('√î', 'O').replace('√ñ', 'O').replace('√í', 'O')
                               .replace('√é', 'I').replace('√è', 'I').replace('√å', 'I')
                               .replace('√á', 'C').replace('√ë', 'N'))
                pyautogui.typewrite(text_fallback)
                print("‚ö†Ô∏è Texte ins√©r√© sans accents (fallback)")
            except:
                print("‚ùå Impossible d'ins√©rer le texte")
    
    def show_ready_indicator(self):
        """Affiche l'indicateur 'mod√®le charg√©' en bas √† droite"""
        def create_ready_indicator():
            try:
                indicator = tk.Tk()
                indicator.title("Ready")
                indicator.configure(bg='#10b981')  # Vert moderne
                indicator.overrideredirect(True)
                indicator.attributes('-topmost', True)
                indicator.attributes('-alpha', 0.95)

                # Positionner en haut √† droite
                indicator.update_idletasks()
                screen_width = indicator.winfo_screenwidth()
                indicator.geometry(f"180x60+{screen_width-200}+20")

                # Label avec ic√¥ne et texte
                label = tk.Label(indicator, text="‚úì Whisper Ready",
                               bg='#10b981', fg='white',
                               font=('Segoe UI', 14, 'bold'))
                label.pack(expand=True)

                # Fermer automatiquement apr√®s 3 secondes
                indicator.after(3000, indicator.destroy)

                indicator.mainloop()

            except Exception as e:
                print(f"Erreur cr√©ation indicateur ready: {e}")

        # Lancer dans un thread s√©par√©
        ready_thread = threading.Thread(target=create_ready_indicator, daemon=True)
        ready_thread.start()

    def show_recording_indicator(self):
        """Affiche l'indicateur d'enregistrement en haut √† droite"""
        def create_indicator():
            try:
                # Cr√©er une nouvelle fen√™tre tkinter dans ce thread
                indicator = tk.Tk()
                indicator.title("REC")
                indicator.geometry("160x50")
                indicator.configure(bg='SystemButtonFace')  # Fond transparent
                indicator.overrideredirect(True)  # Pas de barre de titre
                indicator.attributes('-topmost', True)  # Toujours au premier plan
                indicator.attributes('-alpha', 0.95)  # L√©g√®rement transparent

                # Positionner en haut √† droite de l'√©cran
                indicator.update_idletasks()
                screen_width = indicator.winfo_screenwidth()
                indicator.geometry(f"160x50+{screen_width-180}+20")

                # Frame avec relief pour simuler coins arrondis
                frame = tk.Frame(indicator, bg='#dc2626', relief='flat', bd=0)
                frame.pack(expand=True, fill='both', padx=3, pady=3)

                # Label avec texte clignotant
                label = tk.Label(frame, text="‚óè REC",
                               bg='#dc2626', fg='white',
                               font=('Segoe UI', 16, 'bold'),
                               bd=0, highlightthickness=0)
                label.pack(expand=True)

                # Stocker la r√©f√©rence
                self.indicator_window = indicator

                # Boucle pour faire clignoter
                def blink():
                    if self.recording and self.indicator_window:
                        try:
                            current_bg = '#991b1b' if label.cget('bg') == '#dc2626' else '#dc2626'
                            label.configure(bg=current_bg)
                            frame.configure(bg=current_bg)
                            indicator.after(500, blink)  # Clignoter toutes les 500ms
                        except:
                            pass

                # D√©marrer le clignotement
                blink()

                # Maintenir la fen√™tre ouverte
                indicator.mainloop()

            except Exception as e:
                print(f"Erreur cr√©ation indicateur: {e}")

        # Lancer l'indicateur dans un thread s√©par√©
        if self.indicator_thread is None or not self.indicator_thread.is_alive():
            self.indicator_thread = threading.Thread(target=create_indicator, daemon=True)
            self.indicator_thread.start()
            time.sleep(0.1)  # Petit d√©lai pour laisser la fen√™tre se cr√©er
    
    def hide_recording_indicator(self):
        """Cache l'indicateur d'enregistrement"""
        try:
            if self.indicator_window:
                self.indicator_window.quit()
                self.indicator_window.destroy()
                self.indicator_window = None
        except Exception as e:
            print(f"Erreur fermeture indicateur: {e}")
    
    def quit_app(self):
        """Quitte l'application"""
        print("Fermeture de l'application...")
        self.running = False

    def run(self):
        """Lance l'application"""
        try:
            while self.running:
                keyboard.wait()
        except KeyboardInterrupt:
            print("\nInterruption par l'utilisateur")
        finally:
            self.cleanup()
    
    def cleanup(self):
        """Nettoie les ressources"""
        if self.recording:
            self.stop_recording()
        
        # Fermer l'indicateur
        self.hide_recording_indicator()
        
        if hasattr(self, 'audio'):
            self.audio.terminate()
        
        print("Ressources nettoy√©es")

if __name__ == "__main__":
    app = VoiceTranscriptionApp()
    app.run()